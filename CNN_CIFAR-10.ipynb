{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJik3FFcftOJ"
      },
      "source": [
        "# PyTorch Convolutional Neural Network (CNN) With CIFAR-10 Color Image Dataset\n",
        "\n",
        "In this example, we demonstrate how to train a CNN model (aka ConvNet)  to classify images from the CIFAR-10 dataset. With the nature of CNN can handle spatial data of images and video, the RGB-color images  of CIFAR-10 can be directly use as input to the model.\n",
        "\n",
        "<img src='https://www.ee.cityu.edu.hk/~lmpo/ee5438/images/cnn_cifar10.png'>\n",
        "\n",
        "\n",
        "The CIFAR-10 dataset is a widely used collection of images that is commonly used to train machine learning and computer vision algorithms\n",
        "\n",
        "- It consists of 60,000 32x32 color images in 10 different classes\n",
        "- Each class contains 6,000 images, with 5,000 images for training and 1,000 images for testing\n",
        "- The 10 different classes in the CIFAR-10 dataset represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks\n",
        "\n",
        "The CIFAR-10 dataset can be split into training set, validation set, and test set in various ways. In this example, the way is to use 45,000 images for training, 5,000 images for validation, and 10,000 images for testing.\n",
        "\n",
        "<!-- <img src='https://corochann.com/wp-content/uploads/2021/09/cifar10_plot.png'> -->\n",
        "\n",
        "\n",
        "References:\n",
        "\n",
        "- https://github.com/nestorojeda/CIFAR-10-CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofe63joJgPg-"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries for working with CIFART-10 dataset and PyTorch.\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import nn,optim,no_grad\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torchinfo import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select runnning environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiUw54yxhPIk",
        "outputId": "f83ebac9-ffe1-4ed6-c75d-b27757e1e0e5"
      },
      "outputs": [],
      "source": [
        "# To configure the usage of a GPU (cuda) or MPS (Apple) if either of them is available\n",
        "has_mps = torch.backends.mps.is_built()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if has_mps else \"cpu\"\n",
        "print(f\"Python versoin: {sys.version_info.major, sys.version_info.minor, sys.version_info.micro}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncZwH9VGFg8G"
      },
      "source": [
        "# Download CIFAR10 Dataset\n",
        "\n",
        "This code snippet helps us download the CIFAR-10 dataset, which is a popular dataset used for training and evaluating deep learning models. The dataset is divided into a training set and a test set.\n",
        "\n",
        "In deep learning, it's common to split the dataset into training, validation, and test sets. However, in this particular example, the validation set is not used. Instead, we only use the training set to train our model. The training set consists of 50,000 samples, and we use these samples to teach our model how to recognize and classify images.\n",
        "\n",
        "**During and after training, the model's performance is evaluated by the test set with 10,000 samples. The test set contains a separate set of samples that were not used to update the model's parameters during the training.** We use this test set to assess how well our trained model can generalize to new, unseen data.\n",
        "\n",
        "By creating DataLoaders, we can easily handle the downloading and loading of the training and test sets, making it convenient for us to train our deep learning model on the CIFAR-10 dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvcTY4wiu3Ra",
        "outputId": "fee6f7f2-9b06-4329-edcf-b0ce8260667c"
      },
      "outputs": [],
      "source": [
        "# Define data transformations for the training and test sets\n",
        "train_transform = transforms.Compose([\n",
        "     transforms.RandomHorizontalFlip(0.5), #data augmentation\n",
        "     transforms.RandomAffine(degrees=(-20, 20), translate=(0.1, 0.1), scale=(0.8, 1.2)), #data augmentation\n",
        "     transforms.ToTensor(), # Convert images to tensors\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))]) # Normalize the image data\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "     transforms.ToTensor(), # Convert images to tensors\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))]) # Normalize the image data\n",
        "\n",
        "# Create the CIFAR10dataset for the training set with 50,000 images\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "\n",
        "# Create the CIFAR10 dataset for the test set with 10,000 images (It is also used as validation set during the training)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# Define the data loaders for the training, validation, and test sets\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the classes for the CIFAR-10 dataset\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4j4KXqhF2Vl"
      },
      "source": [
        "## Visualize image for each class\n",
        "\n",
        "The first step in a classification task is to take a look at the data, make sure it is loaded in correctly, then make any initial observations about patterns in that data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "RTiatFpGwfCT",
        "outputId": "53ea2bcb-69d3-415e-900c-b06b3199a9e9"
      },
      "outputs": [],
      "source": [
        "# Visualize training image for each class\n",
        "sample_images = [train_set.data[np.asarray(train_set.targets) == label][0] for label in range(10)]\n",
        "print(sample_images)\n",
        "# show images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "i = 0\n",
        "for row in axes:\n",
        "  for axis in row:\n",
        "    axis.set_xticks([])\n",
        "    axis.set_yticks([])\n",
        "    axis.set_xlabel(classes[i], fontsize=15)\n",
        "    axis.imshow(sample_images[i])\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw8ZgSUtF7hj"
      },
      "source": [
        "## Define the CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define a residual block\n",
        "class resblock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(resblock,self).__init__()\n",
        "        self.res = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.res(x)\n",
        "        return out + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tPgLqmBveuL"
      },
      "outputs": [],
      "source": [
        "# Define the CNN Model\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.resblock1 = resblock(128,128)\n",
        "        self.resblock2 = resblock(512,512)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.MaxPool2d(4), \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.resblock1(x)\n",
        "        x = self.conv3(x)\n",
        "        # x = self.resblock2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.resblock2(x)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "#generate model summary\n",
        "summary(model=model, input_size=(1, 3, 32, 32), col_width=15,\n",
        "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "        row_settings=['var_names'], verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBPSkx7UGD6_"
      },
      "source": [
        "## Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgmNiARcyP3S"
      },
      "outputs": [],
      "source": [
        "# Create a Models folder to store the checkpoints\n",
        "!mkdir Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y31WChKQiP_k"
      },
      "source": [
        "## Specify Loss Function and Optimizer\n",
        "It's recommended that you use cross-entropy loss for classification. If you look at the documentation (linked above), you can see that PyTorch's cross entropy function applies a softmax funtion to the output layer and then calculates the log loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz26daQyiLTl"
      },
      "outputs": [],
      "source": [
        "# Specify Loss/Cost function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Specify optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoyrcbpYY_jq",
        "outputId": "274df5ac-fda3-4370-e004-f3ad61c59335"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "loss_hist, acc_hist = [], []  # Lists to store training loss and accuracy\n",
        "loss_hist_test, acc_hist_test = [], []  # Lists to store validation loss and accuracy\n",
        "\n",
        "model.to(device)  # Move the model to the specified device (e.g., GPU)\n",
        "\n",
        "print(\"Training was started.\\n\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    time_ckpt = time.time()\n",
        "    print(\"EPOCH:\", epoch, end=\" \")\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    # Training loop\n",
        "    for data in train_loader:\n",
        "        batch, labels = data\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear the gradients\n",
        "        outputs = model(batch)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backward pass (compute gradients)\n",
        "        optimizer.step()  # Update the model's parameters\n",
        "\n",
        "        # Compute training statistics\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_set)  # Average training loss for the epoch\n",
        "    avg_acc = correct / len(train_set)  # Average training accuracy for the epoch\n",
        "    loss_hist.append(avg_loss)\n",
        "    acc_hist.append(avg_acc)\n",
        "\n",
        "    # Validation statistics\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        loss_test = 0.0\n",
        "        correct_test = 0\n",
        "\n",
        "        # Validation loop\n",
        "        for data in test_loader:\n",
        "            batch, labels = data\n",
        "            batch, labels = batch.to(device), labels.to(device)\n",
        "            outputs = model(batch)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "            loss_test += loss.item()\n",
        "\n",
        "        avg_loss_test = loss_test / len(test_set)  # Average validation loss for the epoch\n",
        "        avg_acc_test = correct_test / len(test_set)  # Average validation accuracy for the epoch\n",
        "        loss_hist_test.append(avg_loss_test)\n",
        "        acc_hist_test.append(avg_acc_test)\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "#     scheduler.step(avg_loss_val) # Check the scheduler for updating the learning rate\n",
        "\n",
        "    # Save the model at the end of each epoch\n",
        "    with open(\"Models/lenet5_model_{}.pth\".format(epoch), \"wb\") as f:\n",
        "        model.eval()\n",
        "        pickle.dump(model, f)\n",
        "        model.train()\n",
        "\n",
        "    print(\"Train Loss: {:.3f}\".format(avg_loss * 100), end=\" \")\n",
        "    print(\"Test Loss: {:.3f}\".format(avg_loss_test * 100), end=\" \")\n",
        "    print(\"Train Accuracy: {:.2f}%\".format(avg_acc * 100), end=\" \")\n",
        "    print(\"Test Accuracy: {:.2f}%\".format(avg_acc_test * 100), end=\" \")\n",
        "    print(\"Time: {:.2f}s\".format(time.time() - time_ckpt), end=\" \\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQSfBrXvGGIL"
      },
      "source": [
        "## Plotting Training Statistics\n",
        "\n",
        "Loss is a function of the difference of the network output and the target values. We are minimizing the loss function during training so it should decrease over time. Accuracy is the classification accuracy for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "QsfBnLgXi-ut",
        "outputId": "1e2214d6-9efc-43b4-92d2-64b332bf083f"
      },
      "outputs": [],
      "source": [
        "plots=[(loss_hist,loss_hist_test),(acc_hist,acc_hist_test)]\n",
        "plt_labels=[(\"Training Loss\",\"Test Loss\"),(\"Training Accuracy\",\"Test Accuracy\")]\n",
        "plt_titles=[\"Loss\",\"Accuracy\"]\n",
        "plt.figure(figsize=(20,7))\n",
        "for i in range(0,2):\n",
        "    ax=plt.subplot(1,2,i+1)\n",
        "    ax.plot(plots[i][0],label=plt_labels[i][0])\n",
        "    ax.plot(plots[i][1],label=plt_labels[i][1])\n",
        "    ax.set_title(plt_titles[i])\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxoHZNukGP-6"
      },
      "source": [
        "# Test the Trained Network\n",
        "Finally, we test our best model on previously unseen test data and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sNFx1j-Iw_S",
        "outputId": "bd6cb4aa-d26e-4e87-aad4-3d12de6d156f"
      },
      "outputs": [],
      "source": [
        "# Selecting the best model\n",
        "best_acc = max(acc_hist_test)\n",
        "best_epoch = acc_hist_test.index(best_acc)+1\n",
        "\n",
        "print(\"Best accuracy on test set: {:.2f}%\".format(best_acc*100))\n",
        "print(\"Best epoch: {}\".format(best_epoch))\n",
        "\n",
        "# Load the best model\n",
        "with open(f\"Models/lenet5_model_{best_epoch}.pth\",\"rb\") as f:\n",
        "    model=pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpdEpCI7V0UP"
      },
      "source": [
        "# Recalculate Test Set Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAkC3hX5g-fF"
      },
      "outputs": [],
      "source": [
        "pred_vec = []\n",
        "label_vec = []\n",
        "correct = 0\n",
        "test_loss = 0.0\n",
        "avg_test_loss = 0.0\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        batch, labels = data\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        outputs = model(batch)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        test_loss += loss.item()\n",
        "        pred_vec.extend(predicted.cpu().numpy())  # Convert tensor to numpy array\n",
        "        label_vec.extend(labels.cpu().numpy())  # Convert tensor to numpy array\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_set)\n",
        "\n",
        "pred_vec = np.array(pred_vec)\n",
        "label_vec = np.array(label_vec)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QysE4xdLgu42"
      },
      "source": [
        "# Display the Test Set Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7ncTZQgyXO",
        "outputId": "7c32cb39-0227-43c8-8daf-9cadccf2ec4b"
      },
      "outputs": [],
      "source": [
        "print(F\"Test Loss: {avg_test_loss}\")\n",
        "print(F\"Test Accuracy on the {len(test_set)} test images: {(100 * correct / len(test_set))}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZyOO4aXycE5"
      },
      "source": [
        "# Display the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "adSCgYKr5__0",
        "outputId": "6f7eca7d-61b6-4038-b898-7120200b924c"
      },
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_mat = confusion_matrix(label_vec, pred_vec)\n",
        "# Convert confusion matrix to pandas DataFrame\n",
        "labels = np.unique(label_vec)\n",
        "confusion_df = pd.DataFrame(confusion_mat, index=classes, columns=classes)\n",
        "print(\"Confusion Matrix\")\n",
        "confusion_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W9gkfvykUdw"
      },
      "source": [
        "# Compute the Accuracy, F1-Score, Precision, Recall, Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "uvzXPJGmDcgU",
        "outputId": "1f989a93-c6eb-48e9-b4d2-80a67edbb7ca"
      },
      "outputs": [],
      "source": [
        "# Create a report to show the f1-score, precision, recall\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = pd.DataFrame.from_dict(classification_report(pred_vec,label_vec,output_dict=True)).T\n",
        "report['Label']=[classes[int(x)] if x.isdigit() else \" \" for x in report.index]\n",
        "report=report[['Label','f1-score','precision','recall','support']]\n",
        "report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "houtkD3Go_7n"
      },
      "source": [
        "In the context of classification, 'support' refers to the number of instances or samples in a dataset that belong to a specific class. It represents the frequency or count of occurrences of each class in the dataset.\n",
        "\n",
        "Support values help assess the reliability and generalizability of classification models, as they indicate the amount of data available for each class and the potential challenges associated with imbalanced datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wKISqtUpF62"
      },
      "source": [
        "# Visualize Sample Test Results\n",
        "This cell displays test images and their labels in this format: predicted (ground-truth). The text will be green for accurately classified examples and red for incorrect predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "lXjnxdhbpIfV",
        "outputId": "ac2fec09-10d3-4942-d1ab-6090244b5ca5"
      },
      "outputs": [],
      "source": [
        "# obtain one batch of test images\n",
        "images, labels = next(iter(test_loader))\n",
        "model.cpu()\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds = torch.max(output, 1)\n",
        "\n",
        "# Create a 4x4 grid for displaying the images\n",
        "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "\n",
        "# Iterate over the images and display them in the grid\n",
        "for idx, ax in enumerate(axes.flat):\n",
        "  # Normalize the image tensor to [0, 1] range\n",
        "  image = images[idx].permute(1, 2, 0)\n",
        "  image = (image - image.min()) / (image.max() - image.min())\n",
        "  ax.imshow(image)  # Display the image\n",
        "  ax.axis('off')  # Hide the axes\n",
        "  ax.set_title(\"{}\".format(classes[preds[idx]]),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))  # Add title to the image\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnbXZ607ymH0"
      },
      "source": [
        "# Display 50 Predicted Images\n",
        "We iterate through 50 images and plot them with their corresponding label. We will color the label in blue if our model guessed correct and in red if it failed to predict that class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "XWSpVv_6ypB9",
        "outputId": "2410d111-ce62-4dbf-fcb6-c4b196e4f48e"
      },
      "outputs": [],
      "source": [
        "# Define the loader for all test data\n",
        "test_set_all = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=test_transform)\n",
        "test_loader_all = torch.utils.data.DataLoader(test_set_all, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader_all)\n",
        "images, labels = next(iter(test_loader_all))\n",
        "model.cpu()\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds = torch.max(output, 1)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "for idx in range(50):\n",
        "    # Normalize the image tensor to [0, 1] range\n",
        "    image = images[idx].permute(1, 2, 0)\n",
        "    image = (image - image.min()) / (image.max() - image.min())\n",
        "    ax = fig.add_subplot(5, 10, idx + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(image, interpolation='nearest')\n",
        "\n",
        "    if preds[idx]==labels[idx]:\n",
        "      ax.text(0, 3, str(classes[preds[idx].item()]), color='green')\n",
        "    else:\n",
        "      ax.text(0, 3, str(classes[preds[idx].item()]), color='red')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur3uUCvfGSL6"
      },
      "source": [
        "## Visualize wrongly classified image for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "XPx_mN-ImzXa",
        "outputId": "24f5530e-32d4-49f2-863b-baedb6a22534"
      },
      "outputs": [],
      "source": [
        "# Visualize wrongly classified image for each class\n",
        "pred_vec_all = []\n",
        "correct = 0\n",
        "test_loss = 0.0\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader_all:\n",
        "        batch, labels = data\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        outputs = model(batch)\n",
        "        test_loss=criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pred_vec_all.append(predicted)\n",
        "    pred_vec_all = torch.cat(pred_vec_all)\n",
        "\n",
        "pred_vec_all = pred_vec_all.cpu().numpy()\n",
        "ground_truths = np.asarray(test_set_all.targets)\n",
        "incorrect_mask = pred_vec_all != ground_truths\n",
        "incorrect_images = [test_set_all.data[(ground_truths == label) & incorrect_mask][0] for label in range(10)]\n",
        "pred_results_all = [pred_vec_all[(ground_truths == label) & incorrect_mask][0] for label in range(10)]\n",
        "\n",
        "# show images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "i = 0\n",
        "for row in axes:\n",
        "  for axis in row:\n",
        "    axis.set_xticks([])\n",
        "    axis.set_yticks([])\n",
        "    axis.set_xlabel(\"Predicted: %s\" % classes[pred_results_all[i]], fontsize=10)\n",
        "    axis.imshow(incorrect_images[i], cmap='gray')\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "<p> The CNN architecture contain 4 convolution blocks and 2 modified residual block.\n",
        "<p> The first two convolution block is use to stepwise increase the filter numbers to 128 filters, and pooling into 16x16 size image\n",
        "<p> Next the 128 x 16 x 16 block is input into a residual block, the residual block is not a traditional resdual block as the original input is added after the activation function instead of before the second activation function. The result of added after actiavtion is significantly increrased, a possible reason maybe the input image only contain 32x32 pixel, it is to small, which is the every pixel is informative, so adding them after convolution can keep more information, and the model can reslut better.\n",
        "<p> After the first residual block, next two convolution block also use for getting more filter, get more information from the input.\n",
        "<p> The finnal residual block directly flatten and connect to a linear 512 to 10 layer.\n",
        "<p> The numbers of parameters is only about 6M, but the accuracy is <b>90.54%</b>, which is quite a good result.\n",
        "<p> Data augmentation is implemented, which the image is horizontally flip and random affine.\n",
        "<p> Basically, the idea is get from VGG and Resnet, and because of the small pixel, if the network is too deep, the result is worser, but the use of modified resnet perform a good solution."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
